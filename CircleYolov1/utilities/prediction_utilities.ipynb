{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeBkBy5bJVzi/RIF3jih17"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wYZ-GbmI-RrV"},"outputs":[],"source":["from PIL import Image, ImageDraw, ImageFont\n","from numpy.random.mtrand import randint\n","import matplotlib.pyplot as plt\n","\n","def example_prediction(model, test_dataset, loss_yolo_fn = None, prob_threshold = 0.5, iou_threshold = 0.51):\n","  \"\"\"\n","  Performs object detection on a randomly selected image from the test dataset using the provided model.\n","\n","  Args:\n","      model (torch.nn.Module): The object detection model to be used for inference.\n","      test_dataset (torch.utils.data.Dataset): The dataset containing test images and their corresponding labels.\n","      loss_yolo_fn (torch.nn.Module, optional): The YOLO loss function used for calculating the test loss.\n","          Defaults to None.\n","      prob_threshold (float, optional): The probability threshold for filtering out low-confidence predictions.\n","          Defaults to 0.5.\n","      iou_threshold (float, optional): The IoU threshold for non-maximum suppression to remove redundant predictions.\n","          Defaults to 0.51.\n","\n","  Returns:\n","      PIL.Image.Image: The annotated image with bounding boxes drawn around detected objects.\n","      float: The test loss if a YOLO loss function is provided; otherwise, 0.\n","  \"\"\"\n","  # Randomly select an image and its corresponding labels from the test dataset\n","  n = randint(0,len(test_dataset) - 1)\n","  img, labels = test_dataset[n][0], test_dataset[n][1]\n","  img, labels = img.to(device), labels.to(device) # Move data to the appropriate device\n","\n","  model.eval() # Set the model to evaluation mode\n","  test_loss = 0\n","  with torch.no_grad():\n","    out_label = model(img.unsqueeze(dim = 0))\n","  if loss_yolo_fn:\n","    # Calculate the test loss if a YOLO loss function is provided\n","    loss_fn = loss_yolo_fn(C=1, S=7, B=3, lambda_noobj=0.5, lambda_coord=5)\n","    test_loss = loss_fn(out_label, labels.unsqueeze(dim=0));\n","\n","  # Reshape the model output to the desired format\n","  out_label = out_label.reshape(7, 7, -1)\n","  out_label = out_label.to('cpu') # Move predictions to the CPU\n","\n","  # Filter out low-confidence predictions based on probability threshold\n","  apples = out_labels_apple(labels = out_label, threshold = prob_threshold)\n","\n","  # Perform non-maximum suppression to remove redundant predictions based on IoU thresholding\n","  apples = non_max_suppression(apples, threshold = iou_threshold)\n","\n","  # Get image dimensions\n","  Ch, W, H = img.shape\n","  # Convert the image tensor to a PIL image for visualization\n","  img_pil = Image.fromarray((torch.permute(img.to('cpu'), (1, 2, 0)).numpy() * 255).astype('uint8'))\n","  draw = ImageDraw.Draw(img_pil)\n","  font = ImageFont.load_default()\n","\n","  # Draw bounding boxes (ellipses) around detected objects on the image\n","  for class_idx, prob, x, y, r in apples:\n","    draw.ellipse((x*W-r*W, y*H-r*H, x*W+r*W, y*H+r*H), outline='blue', width=2)\n","\n","    # TO DO:\n","    #color = 'red'\n","    #label_text = f\"{prob:.2f}\"\n","    #text_position = ((x*W-r*W*2,  y*H-r*H*2))\n","    #len_name = len(label_text)\n","    #draw.text(text_position, label_text, font=font, fill='white')\n","\n","  # Return the annotated PIL image and the test loss\n","  return img_pil, float(test_loss)\n","\n","\n","def out_labels_apple(labels, threshold = 0.5, S=7, B=3, C=1):\n","  \"\"\"\n","  Returns bounding boxes for the most confident objects (apples) from the YOLO output labels.\n","\n","  Args:\n","      labels (torch.Tensor): YOLO output labels with shape [S, S, C + 4*B], where\n","          S is the grid size,\n","          C is the number of classes,\n","          and B is the number of bounding boxes per grid cell.\n","      threshold (float, optional): The confidence threshold for filtering out low-confidence predictions.\n","          Defaults to 0.5.\n","      S (int, optional): The grid size. Defaults to 7.\n","      B (int, optional): The number of bounding boxes per grid cell. Defaults to 3.\n","      C (int, optional): The number of classes. Defaults to 1.\n","\n","  Returns:\n","      list: A list of bounding boxes for the most confident objects, represented as [class_idx, probability, x, y, r].\n","  \"\"\"\n","\n","  apples = []\n","\n","  for I in range(S):\n","      for J in range(S):\n","        best_bbox = 0\n","        best_confidence = 0\n","\n","        for bbox in range(B):\n","              if labels[I][J][C+4*bbox] > best_confidence:\n","                best_bbox = bbox\n","                best_confidence = labels[I][J][C+4*bbox]\n","        best_confidence = labels[I][J][C]\n","\n","        if best_confidence >= threshold:\n","          class_idx = torch.argmax(labels[I][J][:C])\n","          prob_xywh = labels[I][J][C+(best_bbox*4):C+(best_bbox*4)+4] # P, X, Y, R\n","          apples.append(torch.cat((torch.tensor([J, I, class_idx]), prob_xywh), dim=0))\n","  #                                 I        J       C         P        X        Y        W        H\n","  #print(apples[0]) -> [tensor([ 0.0000,  0.0000, 14.0000,  1.1343,  0.7461,  0.7626,  0.8706,  0.7561])\n","  for i in range(len(apples)):\n","    apples[i] = [float(apples[i][2]),# Class,\n","                float(apples[i][3]),# Probability\n","                float((apples[i][0]+apples[i][4])/S),# X in whole Image\n","                float((apples[i][1]+apples[i][5])/S),# Y in whole Image\n","                float(apples[i][6])]# R in whole Image\n","  return apples"]}]}